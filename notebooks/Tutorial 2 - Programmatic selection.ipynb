{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5604c79",
   "metadata": {},
   "source": [
    "# PACE Tutorial 2: Analysing Missingness in Synthetic APC Data – Programmatic selection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial notebook builds on (`Tutorial Example.ipynb`), and takes another approach to analysing the data missingness from the same synthetic APC dataset.\n",
    "\n",
    "In the previous tutorial, we used an interactive \"Combination heatmap\" visualization to select unexpected missingness combinations to analyse.\n",
    "\n",
    "**Objectives for this tutorial:**\n",
    "  - Learn how to select particular combinations of missingness programmatically with PACE (rather than interactively)\n",
    "  - Explain unexpected patterns of missing data by using data mining techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc802b6",
   "metadata": {},
   "source": [
    "## Preamble: PACE and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff437aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pace.membership import *\n",
    "from pace.history import *\n",
    "from pace.plots import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa197f",
   "metadata": {},
   "source": [
    "## Load the data and create a PlotSession object\n",
    "\n",
    "As before, we read the data as a Pandas dataframe, and create a PACE `PlotSession` object from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15287ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../examples/datasets/Synthetic_APC_DIAG_Fields.csv\")\n",
    "\n",
    "session = PlotSession(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788704d",
   "metadata": {},
   "source": [
    "From the `PlotSession` object, we can extract all distinct missingness combinations into a dataframe (here called `combinations`).\n",
    "\n",
    "One row of this dataframe represents one unique combination which can be identified by its `intersection_id`.\n",
    "\n",
    "Within a row, a boolean value in a column indicates if the column is missing (`True`) or not (`False`) in this particular combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1650d",
   "metadata": {},
   "source": [
    "We see that there are sixteen distinct missingness patterns in the data, including combination_id `0` with no missing fields.  We visualized these in the last tutorial (along with their count) with the **Combination heatmap** plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39107c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = session.membership().intersections()\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe668c2",
   "metadata": {},
   "source": [
    "> **Note**\n",
    ">\n",
    "> `PlotSession.membership()` returns an object containing the missingness data for a particular selection.\n",
    ">\n",
    "> Passing no argument to `membership()`, as above, returns the missingness data for the entire dataframe (`df`).  An optional `name` argument would allow us to visualise the combinations present in a particular named selection (for example, made interactively from a plot).  See the previous tutorial for more on named selections.\n",
    ">\n",
    "> The call to `membership()` returns a `Membership` object, which supports a number of methods for querying the missingness properties of the data, including `intersections()` that we called above.  See the PACE documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b22984",
   "metadata": {},
   "source": [
    "## Making a programmatic selection\n",
    "\n",
    "In our example, we are interested in unexpected missing values in the diagnosis fields `DIAG_01` to `DIAG_10`. To make the job of identifying these more straightforward, we will work with a subset of the combinations dataframe containing only these fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d74ee",
   "metadata": {},
   "source": [
    "As we learned in the previous example, it is expected in this dataset that if any diagnosis column from `DIAG_02` to `DIAG_10` is missing, then all of the subsequent diagnosis columns should also be missing. Unexpected missingness combinations are those with such 'gaps' in the diagnosis columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46579c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinations_subset = combinations[['DIAG_01','DIAG_02','DIAG_03','DIAG_04','DIAG_05','DIAG_06','DIAG_07','DIAG_08','DIAG_09','DIAG_10']]\n",
    "\n",
    "combinations_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfb259",
   "metadata": {},
   "source": [
    "The next cell contains a function that takes a row of the combinations dataframe as input and returns `True` if there is a gap in this combination. A gap is identified when the values in the row are not monotonically increasing (interpreting `True` as 1 and `False` as 0).\n",
    "\n",
    "Conveniently, a pandas Series has an `is_monotonic_increasing` property that we can use to determine if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_gap(row: pd.Series) -> bool:\n",
    "    \"\"\"Does 'row' have a 'gap' (is it non-monotonic)?\"\"\"\n",
    "\n",
    "    return not row.is_monotonic_increasing\n",
    "\n",
    "## equivalent to\n",
    "\n",
    "# def has_gap(row: pd.Series) -> bool:\n",
    "#    found_missing = False\n",
    "#    for m in row:\n",
    "#        found_missing |= m\n",
    "#        if found_missing and not m:\n",
    "#            return True\n",
    "#    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e5a63",
   "metadata": {},
   "source": [
    "We next apply `has_gap()` to each row of the combinations subset dataframe, to give an array that contains the `combination_id`of all combinations with gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_with_gaps = np.where(combinations_subset.apply(has_gap, axis=1))[0]\n",
    "combinations_with_gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259664f",
   "metadata": {},
   "source": [
    "With the function `PlotSession.add_selection()` we can then add a selection to the PlotSession object based on the identified combinations. \n",
    "\n",
    "Note that we need to give the selection a name (`\"gaps\"` in our example).  This is similar to the `add_plot` function that we encountered last time, and allows us to refer back to the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c52247",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_selection(name=\"gaps\", intersections=combinations_with_gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad198df",
   "metadata": {},
   "source": [
    "Even though we made a selection based on missingness combinations we can retrieve the corresponding record indices of the original dataframe with the `select_records()` function. The function takes the name of the selection as an argument and returns a boolean series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_records = session.selected_records(name=\"gaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4927d",
   "metadata": {},
   "source": [
    "We can visualise our selection with the `add_plot()` function.  We call it below with two arguments:\n",
    "  - The argument `name` is the name for the new plot (and can be used to refer to a more refined selection that we make interactively within it).\n",
    "  - The argument `based_on` is the name of the selection from which we take the data to plot.  Notice that the plot below shows only the combinations that we selected in \"gaps\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233d8c1",
   "metadata": {},
   "source": [
    "The obtained value bar chart highlights a very different pattern of missingness compared with the same visualisation of the entire dataset (see the first plot in the previous tutorial notebook).\n",
    "\n",
    "From this plot, the number of missing values in `DIAG_03` immediately indicates a problem, because it is missing more often than the subsequent diagnosis fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406861f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session.add_plot(name=\"gaps_plot\", based_on=\"gaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f863f",
   "metadata": {},
   "source": [
    "## Explaining unexpected missing combinations – Data mining\n",
    "\n",
    "Now that we have selected the records with gaps, we continue as in the previous tutorial notebook.\n",
    "\n",
    "### Information Gain Ratio\n",
    "\n",
    "The notebook `Information Gain Ratio.ipynb` contains helper functions to calculate the information gain ratio (IGR), which we will use with our example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c44b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Information Gain Ratio.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8f0a7",
   "metadata": {},
   "source": [
    "We want to investigate how homogeneous selected fields are, in terms of the presence (or absence) of the records showing unexpected gaps (patterns of missingness). We will compute the IGR for each column/field specified in `igr_columns` using the function `igr()`. `gaps` represents our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "igr_columns = ['ADMIAGE','ADMIMETH','Mortality','PROCODE3','SEX']\n",
    "igr_result = igr(df[igr_columns], gaps_records)\n",
    "igr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4c8d1",
   "metadata": {},
   "source": [
    "`igr()` allows us to rank multiple columns (in our case, those we name in `igr_columns` below) based on the correlation of their values with records that either are or\n",
    "are not members of selected missing combinations (`gaps`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7788dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "igr_result_sorted = dict(sorted(igr_result.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "plt.bar(igr_result_sorted.keys(), igr_result_sorted.values())\n",
    "plt.xlabel(\"Column\")\n",
    "plt.ylabel(\"Information Gain Ratio (IGR)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c537973a",
   "metadata": {},
   "source": [
    "## Identifying the cause of the missing data for a particular combination\n",
    "\n",
    "As in the previous tutorial, we want to learn more about the cause of the unexpected missingness. We again select the most common missing combination with unexpected gaps (this time programatically) and apply data mining methods on the corresponding records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae9cb9d",
   "metadata": {},
   "source": [
    "To achieve this, we use the method `count_intersection()` on the `membership()` object. This returns a dataframe that contains the missingness patterns (just as the method `intersections()`) and additionally the number of records that show a particular missingness pattern (`_count`). \n",
    "\n",
    "Note that we only consider `combinations_with_gaps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d437873",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_count = session.membership().count_intersections().loc[combinations_with_gaps]\n",
    "gaps_count\n",
    "# _most_freq = \n",
    "# gaps_most_freq = \n",
    "# combination_most_freq\n",
    "# session.add_selection(name=\"gap_most_freq\", intersections=combination_most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce87c7",
   "metadata": {},
   "source": [
    "The count is used to identify the `intersection_id` for the most frequent combination with a gap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1140d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_most_freq = [gaps_count[\"_count\"].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa694c",
   "metadata": {},
   "source": [
    "We make add a selection based on the identified combination and recover the corresponding records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5534c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_selection(name=\"gap_most_freq\", intersections=combination_most_freq)\n",
    "gap_most_freq_records = session.selected_records(name=\"gap_most_freq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2bca5",
   "metadata": {},
   "source": [
    "With these records we can compute the entropy as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_table(feature: pd.Series, target: pd.Series) -> pd.DataFrame:\n",
    "    df_target = pd.DataFrame({\n",
    "        feature.name: feature,\n",
    "        \"_target\": target,\n",
    "    })\n",
    "    df_split = (\n",
    "        df_target\n",
    "        .groupby(feature.name)\n",
    "        .agg({\"_target\": [\"sum\", \"count\"]})\n",
    "    )\n",
    "\n",
    "    df_split[(\"_target\", \"p\")] = (\n",
    "        df_split[(\"_target\", \"sum\")] / df_split[(\"_target\", \"count\")]\n",
    "    )\n",
    "\n",
    "    p = df_split[(\"_target\", \"p\")]\n",
    "    df_split[(\"_target\", \"entropy\")] = (p * np.log(1/p)).fillna(0.0)\n",
    "\n",
    "    df_split.columns = df_split.columns.get_level_values(1)\n",
    "        \n",
    "    return df_split[[\"sum\", \"count\", \"entropy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c059de",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_table(df.loc[gaps_records, \"ADMIMETH\"], gap_most_freq_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7897cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_table(df.loc[gaps_records, \"PROCODE3\"], gap_most_freq_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5f386",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417b182",
   "metadata": {},
   "source": [
    "Another way of investigating the above question is to fit a decision tree of a few levels.\n",
    "\n",
    "First, we one-hot encode the categorical variables (`SEX` and `MORTALITY` only contain two classes, so we do not need to encode these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc738c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = pd.get_dummies(df[igr_columns], columns = [\"PROCODE3\", \"ADMIMETH\"])\n",
    "df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3941bc8",
   "metadata": {},
   "source": [
    "Next, we fit a decision tree with Scikit Learn, using the \"entropy\" criterion, to split on information gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da22671",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(\n",
    "    max_depth=2,\n",
    "    criterion=\"entropy\",\n",
    ")\n",
    "clf = clf.fit(df_enc, gaps_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(\n",
    "    clf,\n",
    "    feature_names=list(df_enc),\n",
    "    filled=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
