{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c51b0e3",
   "metadata": {},
   "source": [
    "# setvis Tutorial 3:  Loading data from a Postgres database\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial notebook is very similar to Tutorial 2, building on Tutorial 1, taking another approach to analysing the data missingness from the same synthetic APC dataset.\n",
    "\n",
    "The difference is that in this tutorial, the dataset resides in a Postgres database.\n",
    "\n",
    "**Objectives for this tutorial:**\n",
    "  - Review how to connect to a Postgres database using psycopg2\n",
    "  - Construct setvis objects (`Membership` and `PlotSession`) from a database connection\n",
    "  - Explain unexpected patterns of missing data by using data mining techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f130ef",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><b>Note:</b> For it to work correctly, this notebook requires that a Postgres server is running and a database containing the Synthetic APC dataset is available.\n",
    "\n",
    "See the notebook at the link below for setup instructions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fdb6e",
   "metadata": {},
   "source": [
    "- [Tutorial 3 (supplemental) - Create the Postgres database.ipynb](./Tutorial%203%20(supplemental)%20-%20Create%20the%20Postgres%20database.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc802b6",
   "metadata": {},
   "source": [
    "## Preamble: setvis and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff437aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setvis import *\n",
    "from setvis.plots import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9afe2",
   "metadata": {},
   "source": [
    "## Load data from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ea4e9",
   "metadata": {},
   "source": [
    "### Set up the database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a2973e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">Modify the cell below with your database configuration</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d44c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBNAME = \"db\"\n",
    "USERNAME = \"ostrickson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=\"localhost\", database=DBNAME, user=USERNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e8131",
   "metadata": {},
   "source": [
    "### Load the missingness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Membership.from_postgres(\n",
    "    conn,\n",
    "    schema=\"diag_example\",\n",
    "    relation=\"synth_apc\",\n",
    "    key=\"Key\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dad139",
   "metadata": {},
   "source": [
    "The `Missingness` data structure resides in memory, but since it uses a compressed representation of the missingess combinations, it has a much smaller memory footprint than the full dataset when stored in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa197f",
   "metadata": {},
   "source": [
    "## Create the PlotSession\n",
    "\n",
    "We have already constructed the base Missingness object. We now create a setvis `PlotSession` object from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15287ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = PlotSession(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788704d",
   "metadata": {},
   "source": [
    "From the `PlotSession` object, we can extract all distinct missingness combinations into a dataframe.\n",
    "\n",
    "One row of this dataframe represents one unique combination which can be identified by its `intersection_id`.\n",
    "\n",
    "Within a row, a boolean value in a column indicates if the column is missing (`True`) or not (`False`) in this particular combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39107c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = session.membership().intersections()\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe668c2",
   "metadata": {},
   "source": [
    "> **Note**\n",
    ">\n",
    "> `PlotSession.membership()` returns an object containing the missingness data for a particular selection.\n",
    ">\n",
    "> Passing no argument to `membership()`, as above, returns the missingness data for the entire dataframe (`df`).  An optional `name` argument would allow us to visualise the combinations present in a particular named selection (for example, made interactively from a plot).  See the previous tutorial for more on named selections.\n",
    ">\n",
    "> The call to `membership()` returns a `Membership` object, which supports a number of methods for querying the missingness properties of the data, including `intersections()` that we called above.  See the setvis documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1650d",
   "metadata": {},
   "source": [
    "We see that there are sixteen distinct missingness patterns in the data, including combination_id `0` with no missing fields.  We visualized these in the last tutorial (along with their count) with the Combination heatmap plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b22984",
   "metadata": {},
   "source": [
    "## Making a programmatic selection\n",
    "\n",
    "In our example, we are interested in unexpected missing values in the diagnosis fields `DIAG_01` to `DIAG_10`. To make the job of identifying these more straightforward, we will work with a subset of the combinations dataframe containing only these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46579c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinations_subset = combinations[['DIAG_01','DIAG_02','DIAG_03','DIAG_04','DIAG_05','DIAG_06','DIAG_07','DIAG_08','DIAG_09','DIAG_10']]\n",
    "\n",
    "combinations_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d74ee",
   "metadata": {},
   "source": [
    "As we learned in the previous example, it is expected in this dataset that if any diagnosis column from `DIAG_02` to `DIAG_10` is missing, then all of the subsequent diagnosis columns should also be missing. Unexpected missingness combinations are those with such 'gaps' in the diagnosis columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfb259",
   "metadata": {},
   "source": [
    "The next cell contains a function that takes a row of the combinations dataframe as input and returns `True` if there is a gap in this combination. A gap is identified when the values in the row are not monotonically increasing (interpreting `True` as 1 and `False` as 0).\n",
    "\n",
    "Conveniently, a pandas Series has an `is_monotonic_increasing` property that we can use to determine if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_gap(row: pd.Series) -> bool:\n",
    "    \"\"\"Does 'row' have a 'gap' (is it non-monotonic)?\"\"\"\n",
    "\n",
    "    return not row.is_monotonic_increasing\n",
    "\n",
    "## equivalent to\n",
    "\n",
    "# def has_gap(row: pd.Series) -> bool:\n",
    "#    found_missing = False\n",
    "#    for m in row:\n",
    "#        found_missing |= m\n",
    "#        if found_missing and not m:\n",
    "#            return True\n",
    "#    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e5a63",
   "metadata": {},
   "source": [
    "We next apply `has_gap()` to each row of the combinations subset dataframe, to give an array that contains the `combination_id`of all combinations with gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_with_gaps = np.where(combinations_subset.apply(has_gap, axis=1))[0]\n",
    "combinations_with_gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259664f",
   "metadata": {},
   "source": [
    "With the function `PlotSession.add_selection()` we can then add a selection to the PlotSession object based on the identified combinations. \n",
    "\n",
    "Note that we need to give the selection a name (`\"gaps\"` in our example).  This is similar to the `add_plot` function that we encountered last time, and allows us to refer back to the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c52247",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_selection(name=\"gaps\", intersections=combinations_with_gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad198df",
   "metadata": {},
   "source": [
    "Even though we made a selection based on missingness combinations we can retrieve the corresponding record indices of the original dataframe with the `select_records()` function. The function takes the name of the selection as an argument and returns a boolean series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_records = session.selected_records(name=\"gaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4927d",
   "metadata": {},
   "source": [
    "We can visualise our selection with the `add_plot()` function.  We call it below with two arguments:\n",
    "  - The argument `name` is the name for the new plot (and can be used to refer to a more refined selection that we make interactively within it).\n",
    "  - The argument `based_on` is the name of the selection from which we take the data to plot.  Notice that the plot below shows only the combinations that we selected in \"gaps\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406861f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session.add_plot(name=\"gaps_plot\", based_on=\"gaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233d8c1",
   "metadata": {},
   "source": [
    "This Value bar chart highlights a very different pattern of missingness compared with the same visualization of all of the data (see the first plot in the previous tutorial notebook).\n",
    "\n",
    "From this plot, the number of missing values in `DIAG_03` immediately indicates a problem, because it is missing more often than the subsequent diagnosis fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a58676",
   "metadata": {},
   "source": [
    "## Explaining unexpected missing combinations â€“ Data mining\n",
    "\n",
    "Now that we have selected the records with gaps, we continue as in the previous tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f863f",
   "metadata": {},
   "source": [
    "The notebook `Information Gain Ratio.ipynb` contains helper functions to calculate the information gain ratio (IGR), which we will use with our example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c44b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Information Gain Ratio.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4c8d1",
   "metadata": {},
   "source": [
    "`igr()` allows us to rank multiple columns (in our case, those we have named in `igr_columns` below) based on the correlation of their values with records that either are or are not members of selected missing combinations (`gaps`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377829a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "igr_columns = [\"ADMIAGE\",\"ADMIMETH\",\"Mortality\",\"PROCODE3\",\"SEX\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64158361",
   "metadata": {},
   "source": [
    "### Load selected columns from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec1614",
   "metadata": {},
   "source": [
    "We have already loaded the *missingness* of each column (into our Missingness object, `m`). For the remaining part of this example, we need the *values* of each column named in `igr_columns`.  We now load these from the database connection into a pandas dataframe, `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00baaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `pandas.read_sql_table` does not work with the psycopg2 connection: use read_sql_query instead\n",
    "\n",
    "query_columns = [sql.Identifier(\"Key\")] + [sql.Identifier(col) for col in igr_columns]\n",
    "\n",
    "query = sql.SQL(\"SELECT {columns} from diag_example.synth_apc\").format(\n",
    "    columns = sql.SQL(\",\").join(query_columns),\n",
    ")\n",
    "\n",
    "df = pd.read_sql_query(query, conn, index_col=\"Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e770f2",
   "metadata": {},
   "source": [
    "### Information Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "igr_result = igr(df, gaps_records)\n",
    "igr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7788dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "igr_result_sorted = dict(sorted(igr_result.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "plt.bar(igr_result_sorted.keys(), igr_result_sorted.values())\n",
    "plt.xlabel(\"Column\")\n",
    "plt.ylabel(\"Information Gain Ratio (IGR)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c3f8d",
   "metadata": {},
   "source": [
    "### Information Gain Ratio: One column at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fb6e51",
   "metadata": {},
   "source": [
    "The cells in this section compute the IGR of each of the columns of interest, as above, but a separate query is performed to load each column.  This approach may be useful in a memory-constrained situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_one_column(conn, col):\n",
    "    key_id = sql.Identifier(\"Key\")\n",
    "    col_id = sql.Identifier(col)\n",
    "\n",
    "    query = sql.SQL(\"SELECT {key_id}, {col_id} from diag_example.synth_apc\").format(\n",
    "        key_id=key_id,\n",
    "        col_id=col_id,\n",
    "    )\n",
    "\n",
    "    return pd.read_sql_query(query, conn, index_col=\"Key\")\n",
    "\n",
    "igr_result2 = {}\n",
    "for col in igr_columns:\n",
    "    igr_result2.update(igr(query_one_column(conn, col), gaps_records))\n",
    "    \n",
    "igr_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5f386",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417b182",
   "metadata": {},
   "source": [
    "Another way of investigating the above question is to fit a decision tree of a few levels.\n",
    "\n",
    "First, we one-hot encode the categorical variables (`SEX` and `MORTALITY` only contain two classes, so we do not need to encode these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc738c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = pd.get_dummies(df, columns = [\"PROCODE3\", \"ADMIMETH\"])\n",
    "df_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3941bc8",
   "metadata": {},
   "source": [
    "Next, we fit a decision tree with Scikit Learn, using the \"entropy\" criterion, to split on information gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da22671",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(\n",
    "    max_depth=2,\n",
    "    criterion=\"entropy\",\n",
    ")\n",
    "clf = clf.fit(df_enc, gaps_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(\n",
    "    clf,\n",
    "    feature_names=list(features),\n",
    "    filled=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
