{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c56e92",
   "metadata": {},
   "source": [
    "# Information Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce88b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.metrics import mutual_info_score, adjusted_mutual_info_score, normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973a400",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c967a5",
   "metadata": {},
   "source": [
    "We define a helper function to compute the entropy $H$ of a random variable from a pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e25553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_entropy(s: pd.Series) -> float:\n",
    "    \"\"\"Compute the entropy from samples in a Pandas series\"\"\"\n",
    "    return entropy(s.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c99da",
   "metadata": {},
   "source": [
    "### Information Gain Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a275d9",
   "metadata": {},
   "source": [
    "The *Information Gain* (also known as *Mutual Information*) of two random variables is defined as:\n",
    "\n",
    "$$ IG(C; A) = H(C) - H(C|A). $$\n",
    "\n",
    "IG can be used when constructing a decision tree as a criterion for choosing the variable on which to split the data, to form the next level of the tree.  In this setting, $C$ is the target class and $A$ is a proposed feature on which to split. The feature that maximises this quantity is chosen to split the data at the next level of the tree. \n",
    "\n",
    "One disadvantage with using information gain for this purpose is that features with a large number of distinct values in a variable can produce to a large value of IG, but choosing such features can typically lead to overfitting.\n",
    "\n",
    "The *Information Gain Ratio* [1] is the ratio of the information gain to the entropy of the feature on which to split:\n",
    "\n",
    "$$ IGR(C; A) = \\frac{H(C) - H(C|A)}{H(A)} $$\n",
    "\n",
    "Compared to IG, this is biased against features with a large number of distinct values (that have a large $H(A)$).\n",
    "\n",
    "Below, we compute this from features contained in a dataframe `df_features` and a target class in the series `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def igr(df_features: pd.DataFrame, target: pd.Series) -> Dict[Any, float]:\n",
    "    \"\"\"\n",
    "    Calculate the information gain ratio for each feature in a dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_features : Dataframe\n",
    "        The features for which the information gain ratio will be calculated\n",
    "    target : Series\n",
    "        The targets for which the information gain ratio with each feature will be calculated\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of feature names to information gain ratio, for each feature in df_features.\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        col: mutual_info_score(df_features[col], target) / series_entropy(df_features[col])\n",
    "        for col in df_features.columns\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cff3a7",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916263d2",
   "metadata": {},
   "source": [
    "- [1] Quinlan, J. Ross. \"Induction of decision trees.\" Machine learning 1.1 (1986): 81-106 [(link)](https://doi.org/10.1007/BF00116251)\n",
    "- [2] https://en.wikipedia.org/wiki/Information_gain_ratio\n",
    "- [3] https://en.wikipedia.org/wiki/Information_gain_in_decision_trees\n",
    "- [4] https://stats.stackexchange.com/questions/319590/what-is-the-range-of-information-gain-ratio/360901#360901"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
